<div style = "margin-left: auto;margin-right: auto;width: 80em;
padding-top: 50px;padding-bottom: 50px;">   

<html>
<head>
<title>
DS 801: Advanced Optimization for Data Science
</title>
<meta charset="utf-8">
</head>
<center><h2>DS 801: Advanced Optimization for Data Science, Spring 2024</h2></center>
<center><h3>MW 9:00 - 10:15 am, E2-2 1501</h3></center>

<body>
<p><b>Instructor</b>: <a href="https://dabeenl.github.io">Dabeen Lee</a> (E2-2 #2109)</br>
<b>Email</b>: dabeenl [at] kaist [dot] ac [dot] kr</p>

<p><b>Teaching Assistant</b>: Seoungbin Bae  (Email: sbbae3 [at] gmail [dot] com)</p>

<p><b>Text</b>: No required text, but the following materials are helpful.</br></br>

<p><b>Syllabus</b> (<a href="DS801_2024_Syllabus.pdf">pdf</a>)</p>

<p>In today's fast-paced world driven by data, the ability to extract valuable insights and make informed decisions is more crucial than ever. Optimization, the process of finding the best solution among a set of alternatives, lies at the heart of this endeavor. From predicting customer behavior to optimizing supply chains, from designing machine learning models to solving complex decision-making problems, optimization techniques play a pivotal role in harnessing the power of data for practical applications. In this course, we will embark on a journey to explore the fundamental principles, algorithms, and applications of optimization in the context of data science. Through a blend of theory, practical examples, and hands-on exercises, we will equip ourselves with the necessary tools and techniques to tackle real-world optimization challenges in data-driven decision-making. There are no formal prerequisites, but basic knowledge of mathematical optimization and convex analysis will be assumed.</p>
  
<h3>Lecture notes</h3>
<ol>
<li> Mon 2/26: introduction (<a href="DS801_2024_lecture1_note.pdf">lecture note</a>)</li>
<li> Wed 2/28: convex optimization basics (<a href="DS801_2024_lecture2_note.pdf">lecture note</a>)</li>
<li> Mon 3/04: introduction to gradient descent (<a href="DS801_2024_lecture3_note.pdf">lecture note</a>, <a href="Lecture3_Gradient_Descent.html">code</a>)</li>
<li> Wed 3/06: gradient descent for smooth functions, adaptive gradient (AdaGrad) (<a href="DS801_2024_lecture4_note.pdf">lecture note</a>)</li>
<li> Mon 3/11: gradient descent for strongly convex functions, regularization (<a href="DS801_2024_lecture5_note.pdf">lecture note</a>, <a href="Lecture5_Strong_Convexity_Regularization.html">code</a>)</li>
</ol>

<h3>Assignments</h3>
<ol type="1">
</ol>
