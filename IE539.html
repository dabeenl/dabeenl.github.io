<div style = "margin-left: auto;margin-right: auto;width: 80em;
padding-top: 50px;padding-bottom: 50px;">   

<html>
<head>
<title>
IE 539: Convex Optimization
</title>
<meta charset="utf-8">
</head>
<center><h2>IE 539: Convex Optimization, Fall 2023</h2></center>
<center><h3>MW 4:00 - 5:30 pm, E2-2 B105</h3></center>

<body>
<p><b>Instructor</b>: <a href="https://dabeenl.github.io">Dabeen Lee</a> (E2-2 #2109)</br>
<b>Office Hours</b>: Tue 2:00 - 3:00 pm</br>
<b>Email</b>: dabeenl [at] kaist [dot] ac [dot] kr</p>

<p><b>Teaching Assistant</b>: Haeun Jeon (Email: haeun39 [at] kaist [dot] ac [dot] kr)</p>

<p><b>Text</b>: No required text, but the following materials are helpful.</br></br>
<u>Recommended textbooks and lecture notes</u>
<ul>
<li> <a href="https://stanford.edu/~boyd/cvxbook/">Convex Optimization</a> by Boyd and Vandenberghe.</li>
<li> <a href="https://arxiv.org/abs/1405.4980">Convex Optimization: Algorithms and Complexity</a> by Bubeck.</li>
<li> <a href="https://www2.isye.gatech.edu/~nemirovs/">Lectures on Modern Convex Optimization</a> by Ben-Tal and Nemirovski.</li>
</ul></p>

<p><b>Syllabus</b> (<a href="IE539_2023_Syllabus.pdf">pdf</a>)</p>

<p>Big data has introduced many opportunities to make better decision-making based on a data-driven approach, and many of the relevant decision-making problems can be posed as optimization models that have special properties such as convexity and smoothness. From this course, a graduate-level student will learn fundamental and comprehensive convex optimization knowledge in theory (convex analysis, optimality conditions, duality) and algorithms (gradient descent and variants, Frank-Wolfe, and proximal methods). We will also cover some application areas including statistical estimation, finance (e.g., portfolio optimization), machine learning, and data science.</p>

<h3>Lecture notes</h3>
<ol>
<li> Mon 8/28: introduction (<a href="IE539_2023_lecture0.pdf">slides</a>), linear algebra review (<a href="IE539_2023_lecture1_note.pdf">note</a>)</li>
<li> Wed 8/30: matrix calculus review, convex sets (<a href="IE539_2023_lecture2_note.pdf">note</a>)</li>
<li> Mon 9/04: convex functions, first-order and second-order characterizations of convex functions (<a href="IE539_2023_lecture3_note.pdf">note</a>)</li>
<li> Wed 9/06: operations preserving convexity, convex optimization problems I (Portfolio optimization, Uncertainty quantification) (<a href="IE539_2023_lecture4_note.pdf">note</a>)</li>  
<li> Mon 9/11: convex optimization problems II (SVM, LASSO, Facility location), classes of convex programming I (LP)  (<a href="IE539_2023_lecture5_note.pdf">note</a>)</li>  
<li> Wed 9/13: classes of convex programming II (QP, SDP, Conic programming) (<a href="IE539_2023_lecture6_note.pdf">note</a>)</li>  
<li> Mon 9/18: conic duality, SOCP and applications (<a href="IE539_2023_lecture7_note.pdf">note</a>)</li>  
<li> Wed 9/20: optimality conditions, introduction to gradient descent (<a href="IE539_2023_lecture8_note.pdf">note</a>)</li>  
<li> Mon 9/25: convergence of gradient descent (<a href="IE539_2023_lecture9_note.pdf">note</a>)</li>  
<li> Wed 9/27: subgradient method, gradient descent for smooth functions (<a href="IE539_2023_lecture10_note.pdf">note</a>)</li> 
<li> Thu 10/05: convergence of gradient descent for functions that are smooth and strongly convex (<a href="IE539_2023_lecture11_note.pdf">note</a>)</li> 
<li> Wed 10/11: projected gradient descent, Nesterov's acceleration, oracle complexity lower bounds (<a href="IE539_2023_lecture12_note.pdf">note</a>)</li> 
<li> Mon 10/23: Frank-Wolfe algorithm, introduction to online convex optimization (<a href="IE539_2023_lecture13_note.pdf">note</a>)</li> 
<li> Wed 10/25: online and stochastic gradient descent algorithms (<a href="IE539_2023_lecture14_note.pdf">note</a>)</li>
<li> Mon 10/30: convergence of stochastic gradient descent, proximal gradient descent (<a href="IE539_2023_lecture15_note.pdf">note</a>)</li> 
<li> Wed 11/01: convergence of proximal gradient descent, proximal point algorithm (<a href="IE539_2023_lecture16_note.pdf">note</a>)</li> 
<li> Mon 11/06: KKT conditions, Lagrangian duality (<a href="IE539_2023_lecture17_note.pdf">note</a>)</li> 
<li> Wed 11/08: saddle point problem, Fenchel conjugate (<a href="IE539_2023_lecture18_note.pdf">note</a>)</li>
<li> Mon 11/13: Fenchel duality (<a href="IE539_2023_lecture19_note.pdf">note</a>)</li>
<li> Wed 11/15: dual gradient method, Moreau-Yosida smoothing (<a href="IE539_2023_lecture20_note.pdf">note</a>)</li>
<li> Mon 11/20: augmented Lagrangian method, alternating direction method of multipliers (ADMM) (<a href="IE539_2023_lecture21_note.pdf">note</a>)</li>
<li> Wed 11/22: Newton's method (<a href="IE539_2023_lecture22_note.pdf">note</a>)</li>
<li> Mon 11/27: Quasi-Newton methods (<a href="IE539_2023_lecture23_note.pdf">note</a>)</li>
</ol>

<h3>Assignments</h3>
<ol type="1">
  <li> Assignment 1 (<a href="IE539_2023_assignment1.pdf">pdf</a>)</li>
  <li> Assignment 2 (<a href="IE539_2023_assignment2.pdf">pdf</a>)</li>
  <li> Assignment 3 (<a href="IE539_2023_assignment3.pdf">pdf</a>)</li>
  <li> Assignment 4 (<a href="IE539_2023_assignment4.pdf">pdf</a>)</li>
</ol>

<h3>Past versions</h3>
<p><a href="https://dabeenl.github.io/IE539_2022">Fall 2022</a></br>
</p>

</body>
</html>
</div>
