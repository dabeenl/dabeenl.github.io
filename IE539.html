<div style = "margin-left: auto;margin-right: auto;width: 80em;
padding-top: 50px;padding-bottom: 50px;">   

<html>
<head>
<title>
IE 539: Convex Optimization
</title>
<meta charset="utf-8">
</head>
<center><h2>IE 539: Convex Optimization, Fall 2024</h2></center>
<center><h3>MW 2:30 - 3:40 pm, E2-2 B105</h3></center>

<body>
<p><b>Instructor</b>: <a href="https://dabeenl.github.io">Dabeen Lee</a> (E2-2 #2109)</br>
<b>Office Hours</b>: Tue 2:00 - 3:00 pm</br>
<b>Email</b>: dabeenl [at] kaist [dot] ac [dot] kr</p>

<p><b>Teaching Assistant</b>: Jaehyun Park (Email: jhpark [at] kaist [dot] ac [dot] kr) and Junyeop Kwon (Email: junyeopk [at] kaist [dot] ac [dot] kr)</p>

<p><b>Text</b>: No required text, but the following materials are helpful.</br></br>
<u>Recommended textbooks and lecture notes</u>
<ul>
<li> <a href="https://stanford.edu/~boyd/cvxbook/">Convex Optimization</a> by Boyd and Vandenberghe.</li>
<li> <a href="https://arxiv.org/abs/1405.4980">Convex Optimization: Algorithms and Complexity</a> by Bubeck.</li>
<li> <a href="https://www2.isye.gatech.edu/~nemirovs/">Lectures on Modern Convex Optimization</a> by Ben-Tal and Nemirovski.</li>
</ul></p>

<p><b>Syllabus</b> (<a href="IE539_2024_Syllabus.pdf">pdf</a>)</p>

<p>Big data has introduced many opportunities to make better decision-making based on a data-driven approach, and many of the relevant decision-making problems can be posed as optimization models that have special properties such as convexity and smoothness. From this course, a graduate-level student will learn fundamental and comprehensive convex optimization knowledge in theory (convex analysis, optimality conditions, duality) and algorithms (gradient descent and variants, Frank-Wolfe, and proximal methods). We will also cover some application areas including statistical estimation, finance (e.g., portfolio optimization), machine learning, and data science.</p>

<h3>Lecture notes</h3>
<ol>
<li> Mon 9/02: introduction (<a href="IE539_2024_lecture0.pdf">slides</a>), linear algebra review (<a href="IE539_2024_lecture1_note.pdf">note</a>)</li>
<li> Wed 9/04: matrix calculus review, convex sets (<a href="IE539_2024_lecture2_note.pdf">note</a>)</li>
<li> Mon 9/09: convex functions, first-order and second-order characterizations of convex functions (<a href="IE539_2024_lecture3_note.pdf">note</a>)</li>
<li> Wed 9/11: operations preserving convexity, convex optimization problems I (Portfolio optimization, Uncertainty quantification) (<a href="IE539_2024_lecture4_note.pdf">note</a>)</li>  
<li> Mon 9/23: convex optimization problems II (SVM, LASSO, Facility location), classes of convex programming I (LP)  (<a href="IE539_2024_lecture5_note.pdf">note</a>)</li>  
<li> Wed 9/25: classes of convex programming II (QP, SDP, Conic programming) (<a href="IE539_2024_lecture6_note.pdf">note</a>)</li>  
<li> Mon 9/30: conic duality, SOCP and applications (<a href="IE539_2024_lecture7_note.pdf">note</a>)</li>  
<li> Wed 10/02: optimality conditions, introduction to gradient descent (<a href="IE539_2024_lecture8_note.pdf">note</a>)</li>  
<li> Mon 10/07: convergence of gradient descent (<a href="IE539_2024_lecture9_note.pdf">note</a>)</li>  
<li> Mon 10/14: subgradient method, gradient descent for smooth functions, projected gradient descent (<a href="IE539_2024_lecture10_note.pdf">note</a>)</li> 
<li> Wed 10/16: convergence of gradient descent for functions that are smooth and strongly convex (<a href="IE539_2024_lecture11_note.pdf">note</a>)</li> 
<li> Mon 10/28: oracle complexity lower bounds, Nesterov's acceleration, Frank-Wolfe algorithm (<a href="IE539_2024_lecture12_note.pdf">note</a>)</li> 
<li> Wed 10/30: stochastic gradient descent (<a href="IE539_2024_lecture13_note.pdf">note</a>)</li>
<li> Mon 11/04: proximal gradient descent (<a href="IE539_2024_lecture14_note.pdf">note</a>)</li> 
<li> Wed 11/06: ISTA and FISTA for LASSO (<a href="IE539_2024_lecture15_note.pdf">note</a>)</li> 
<li> Mon 11/11: proximal point algorithm, Lagrangian duality (<a href="IE539_2024_lecture16_note.pdf">note</a>)</li> 
<li> Wed 11/13: saddle point problem, Fenchel duality I (<a href="IE539_2024_lecture17_note.pdf">note</a>)</li>
<li> Mon 11/18: Fenchel duality II (<a href="IE539_2024_lecture18_note.pdf">note</a>)</li>
<li> Wed 11/20: dual gradient method, Moreau-Yosida smoothing (<a href="IE539_2024_lecture19_note.pdf">note</a>)</li>
<li> Mon 11/25: augmented Lagrangian method, alternating direction method of multipliers (ADMM) (<a href="IE539_2024_lecture20_note.pdf">note</a>)</li>
<li> Wed 11/27: Newton's method (<a href="IE539_2024_lecture21_note.pdf">note</a>)</li>
<li> Mon 12/02: quasi-Newton methods (<a href="IE539_2024_lecture22_note.pdf">note</a>)</li>
<li> Wed 12/04: barrier method (<a href="IE539_2024_lecture23_note.pdf">note</a>)</li>
<li> Mon 12/09: primal-dual interior point method (<a href="IE539_2024_lecture24_note.pdf">note</a>)</li>
</ol>

<h3>Assignments</h3>
<ol type="1">
  <li> Assignment 1 (<a href="IE539_2024_assignment1.pdf">pdf</a>)</li>
  <li> Assignment 2 (<a href="IE539_2024_assignment2.pdf">pdf</a>)</li>
  <li> Assignment 3 (<a href="IE539_2024_assignment3.pdf">pdf</a>)</li>
  <li> Assignment 4 (<a href="IE539_2024_assignment4.pdf">pdf</a>)</li>
  <li> Assignment 5 (<a href="IE539_2024_assignment5.pdf">pdf</a>)</li>
</ol>

<h3>Final exam</h3>
<p>(<a href="IE539_2024_final_exam.pdf">file</a>)</p>

<h3>Past versions</h3>
<p><a href="https://dabeenl.github.io/IE539_2023">Fall 2023</a></br>
<p><a href="https://dabeenl.github.io/IE539_2022">Fall 2022</a></br>
</p>


</body>
</html>
</div>
